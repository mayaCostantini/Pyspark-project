# Analyzing data with Spark 

## Presentation of the project and setup
The goal of this project is to use the Apache Spark Python API to analyze a public Google dataset from 2011 containing information about a cluster of 12500 machines, recorded for a duration of 29 days. 
The data is available on Google Cloud via the GSUtil tool, a Python application to get a command line access to Cloud Storage.
The instructions to install GSUtil are available via the following link : 

https://cloud.google.com/storage/docs/gsutil_install

This project was built with MacOS Catalina version 10.15.1, Python 3.8 and the Visual Studio Code environment. 


